{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "import threading\n",
    "\n",
    "import requests\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import ta\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine(\"mysql+pymysql://daddy_user:69Dnq4BQg6SCcf3M@localhost/daddy\")\n",
    "\n",
    "def get_data(url, index, proxy):    \n",
    "    global results\n",
    "    global threads\n",
    "        \n",
    "    if proxy == None:\n",
    "        res = requests.get(url, timeout=2)\n",
    "    else:\n",
    "        proxies = {\n",
    "          \"http\": \"http://\" + proxy,\n",
    "          \"https\": \"https://\" + proxy,\n",
    "        }\n",
    "        res = requests.get(url, proxies=proxies, timeout=2)\n",
    "        \n",
    "    results[index] = pd.DataFrame(json.loads(res.text))\n",
    "\n",
    "def get_df(start_time, proxy=None, total_range=30):\n",
    "    global threads\n",
    "    global results\n",
    "    \n",
    "    start_time = pd.to_datetime(start_time).tz_localize(None)\n",
    "    \n",
    "    if start_time.date() == datetime.datetime.utcnow().date():\n",
    "        urls = [\"https://www.bitmex.com/api/v1/trade?symbol=XBTUSD&count={}&start={}&reverse=false&startTime={}\".format(1000, i * 1000, start_time) for i in range(total_range)]\n",
    "    else:\n",
    "        urls = [\"https://www.bitmex.com/api/v1/trade?symbol=XBTUSD&count={}&start={}&reverse=false&startTime={}&endTime={}\".format(1000, i * 1000, start_time, pd.to_datetime(start_time.date() + pd.Timedelta(days=1))) for i in range(total_range)]\n",
    "    \n",
    "    threads = [None] * len(urls)\n",
    "    results = [None] * len(urls)\n",
    "    \n",
    "    for i in range(len(threads)):\n",
    "        threads[i] = threading.Thread(target=get_data, args=(urls[i], i, proxy))\n",
    "        threads[i].start()\n",
    "    \n",
    "    for i in range(len(threads)):\n",
    "        threads[i].join()\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for curr_df in results:\n",
    "        df = df.append(curr_df, ignore_index=True)\n",
    "                    \n",
    "    return df\n",
    "\n",
    "def manual_scrape(scrape_from, sleep=True):\n",
    "    print(\"Manual scrape for {}\".format(scrape_from))\n",
    "    proxy_df = pd.read_csv('proxies', sep=':', header=None)\n",
    "    proxy_df.columns = ['proxy', 'port', 'username', 'password']\n",
    "\n",
    "    proxy_df['proxy_string'] =  proxy_df['username'] + \":\" + proxy_df['password'] + \"@\" + proxy_df['proxy'] + \":\" + proxy_df['port'].astype(str)\n",
    "    proxy_list = list(proxy_df['proxy_string'])\n",
    "    at_once = len(proxy_list) + 1\n",
    "    all_df = pd.DataFrame()\n",
    "    completed = False\n",
    "    \n",
    "    while True:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for i in range(at_once):\n",
    "            if i == 0:\n",
    "                curr_df = get_df(scrape_from)\n",
    "            else:\n",
    "                curr_df = get_df(scrape_from, proxy=proxy_list[i-1])\n",
    "                \n",
    "            all_df = all_df.append(curr_df, ignore_index=True)\n",
    "            all_df = all_df.dropna(subset=['timestamp'], how='all')\n",
    "            \n",
    "            scrape_from = all_df.iloc[-1]['timestamp']\n",
    "            print(\"Got {} data till {}\".format(len(curr_df), scrape_from))\n",
    "            \n",
    "            if len(curr_df) < 1000:\n",
    "                completed = True\n",
    "                break\n",
    "         \n",
    "        total_time_taken = time.time() - start_time\n",
    "        \n",
    "        to_sleep = int(60 - total_time_taken) + 1\n",
    "        \n",
    "        if completed == True:\n",
    "            break\n",
    "\n",
    "        if to_sleep > 0:\n",
    "            if sleep == True:\n",
    "                print(\"Sleeping {} seconds\".format(to_sleep))\n",
    "                time.sleep(to_sleep)\n",
    "        else:\n",
    "            print(\"No need to sleep\")\n",
    "            \n",
    "    \n",
    "    all_df['timestamp'] = pd.to_datetime(all_df['timestamp'])\n",
    "    all_df['timestamp'] = all_df['timestamp'].dt.tz_localize(None)\n",
    "    all_df = all_df.sort_values('timestamp').reset_index(drop=True)\n",
    "            \n",
    "    return all_df\n",
    "\n",
    "def aws_scrape(name):\n",
    "    print(\"AWS Scrape for {}\".format(name))\n",
    "    url = \"https://s3-eu-west-1.amazonaws.com/public.bitmex.com/data/trade/{}\".format(name)\n",
    "    r = requests.get(url)\n",
    "    \n",
    "    with open('temp', 'wb') as f:\n",
    "        f.write(r.content)\n",
    "        \n",
    "    df = pd.read_csv('temp', compression='gzip')\n",
    "    os.remove('temp')\n",
    "    aws_df = df[df['symbol'] == 'XBTUSD']\n",
    "    aws_df['timestamp'] = pd.to_datetime(aws_df['timestamp'], format=\"%Y-%m-%dD%H:%M:%S.%f\")\n",
    "    aws_df = aws_df.sort_values('timestamp').reset_index(drop=True)\n",
    "    return aws_df\n",
    "\n",
    "def get_bitmex_data(start, end, sleep=True):\n",
    "    all_df = []\n",
    "\n",
    "    for scrape_date in pd.date_range(start, end):\n",
    "        if scrape_date.date() == datetime.datetime.utcnow().date() - pd.Timedelta(days=1):\n",
    "            curr_time = datetime.datetime.utcnow()\n",
    "            if curr_time.time() > datetime.time(5,41):\n",
    "                df = aws_scrape(scrape_date.strftime(\"%Y%m%d.csv.gz\"))\n",
    "            else:\n",
    "                df = manual_scrape(scrape_date, sleep=sleep)\n",
    "        elif scrape_date.date() == datetime.datetime.utcnow().date():\n",
    "            df = manual_scrape(scrape_date,  sleep=sleep)\n",
    "        else:\n",
    "            df = aws_scrape(scrape_date.strftime(\"%Y%m%d.csv.gz\"))\n",
    "\n",
    "\n",
    "        all_df.append(df)\n",
    "    \n",
    "    return pd.concat(all_df, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_trades():\n",
    "    run_again = False\n",
    "    end = pd.to_datetime(datetime.datetime.utcnow()).date()\n",
    "    original_start = end - pd.Timedelta(days=20)\n",
    "    \n",
    "    try:\n",
    "        start = pd.read_sql('SELECT timestamp FROM trades ORDER BY timestamp DESC LIMIT 1', engine).iloc[0]['timestamp']\n",
    "    except:\n",
    "        start = original_start\n",
    "        end = end - pd.Timedelta(days=2)\n",
    "        run_again = True\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            if run_again == False:\n",
    "                end = pd.to_datetime(datetime.datetime.utcnow())\n",
    "                \n",
    "            print(\"{} to {}\".format(start, end))\n",
    "            df = get_bitmex_data(start, end)\n",
    "            df = df[['timestamp', 'symbol', 'side', 'size', 'price', 'homeNotional', 'foreignNotional']]\n",
    "            df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "            df.to_sql('trades', con = engine, if_exists = 'append', chunksize = None, index=None)                \n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(\"Exception: {}. Retrying in 5 secs\".format(str(e)))\n",
    "            time.sleep(5)\n",
    "    \n",
    "    if run_again == True:\n",
    "        update_trades()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-18 00:00:00 to 2021-01-19 04:11:28.847698\n",
      "Manual scrape for 2021-01-18 00:00:00\n",
      "Got 30000 data till 2021-01-18T02:33:00.568Z\n",
      "Got 30000 data till 2021-01-18T04:39:05.102Z\n",
      "Got 30000 data till 2021-01-18T07:04:44.115Z\n",
      "Got 30000 data till 2021-01-18T08:48:23.581Z\n",
      "Got 30000 data till 2021-01-18T11:03:16.526Z\n",
      "Got 30000 data till 2021-01-18T12:09:50.120Z\n",
      "Sleeping 40 seconds\n",
      "Got 30000 data till 2021-01-18T13:23:05.839Z\n",
      "Got 30000 data till 2021-01-18T14:56:08.455Z\n",
      "Got 30000 data till 2021-01-18T16:44:07.924Z\n",
      "Got 30000 data till 2021-01-18T18:22:56.640Z\n",
      "Got 30000 data till 2021-01-18T20:55:57.178Z\n",
      "Got 30000 data till 2021-01-18T23:58:07.095Z\n",
      "Sleeping 39 seconds\n",
      "Got 397 data till 2021-01-18T23:59:59.842Z\n",
      "Manual scrape for 2021-01-19 00:00:00\n",
      "Exception: ['timestamp']. Retrying in 5 secs\n",
      "2021-01-18 00:00:00 to 2021-01-19 04:13:37.165748\n",
      "Manual scrape for 2021-01-18 00:00:00\n",
      "Got 3054 data till 2021-01-18T01:21:12.395Z\n",
      "Got 30000 data till 2021-01-18T03:45:25.846Z\n",
      "Got 30000 data till 2021-01-18T06:06:10.944Z\n",
      "Got 30000 data till 2021-01-18T07:59:13.110Z\n",
      "Got 30000 data till 2021-01-18T10:12:09.832Z\n",
      "Got 30000 data till 2021-01-18T12:00:22.500Z\n",
      "Sleeping 40 seconds\n",
      "Got 30000 data till 2021-01-18T12:49:17.949Z\n",
      "Got 30000 data till 2021-01-18T14:33:48.113Z\n",
      "Got 30000 data till 2021-01-18T16:08:41.013Z\n",
      "Got 30000 data till 2021-01-18T17:39:37.487Z\n",
      "Got 30000 data till 2021-01-18T20:12:17.763Z\n",
      "Got 30000 data till 2021-01-18T23:02:57.255Z\n",
      "Sleeping 37 seconds\n",
      "Got 11397 data till 2021-01-18T23:59:59.842Z\n",
      "Got 1 data till 2021-01-18T23:59:59.842Z\n",
      "Manual scrape for 2021-01-19 00:00:00\n",
      "Got 2056 data till 2021-01-19T00:06:30.318Z\n",
      "Got 2056 data till 2021-01-19T01:43:19.129Z\n",
      "Got 30000 data till 2021-01-19T03:46:02.445Z\n",
      "Got 6414 data till 2021-01-19T04:15:54.280Z\n",
      "Got 4 data till 2021-01-19T04:15:57.282Z\n"
     ]
    }
   ],
   "source": [
    "update_trades()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_significant_traders(df):\n",
    "    df = df[['timestamp', 'side', 'homeNotional', 'foreignNotional']]\n",
    "    df = df.groupby(['timestamp', 'side']).sum() \n",
    "    df = df.reset_index()\n",
    "    df = df[df['foreignNotional'] > 500]\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    df['price'] = df['foreignNotional']/df['homeNotional']\n",
    "    df = df.sort_values('timestamp')\n",
    "    df = df.drop_duplicates()\n",
    "    return df\n",
    "\n",
    "def get_features(curr_df):\n",
    "    ser = {}\n",
    "    curr_df = curr_df.sort_values('timestamp')\n",
    "    \n",
    "    if len(curr_df) > 0:\n",
    "        ser['open'] = curr_df.iloc[0]['price']\n",
    "        ser['high'] = curr_df['price'].max()\n",
    "        ser['low'] = curr_df['price'].min()\n",
    "        ser['close'] = curr_df.iloc[-1]['price']\n",
    "        ser['volume'] = curr_df['foreignNotional'].sum()\n",
    "    else:\n",
    "        ser['open'] = np.nan\n",
    "        ser['high'] = np.nan\n",
    "        ser['low'] = np.nan\n",
    "        ser['close'] = np.nan\n",
    "        ser['volume'] = np.nan\n",
    "        \n",
    "    buy_orders = curr_df[curr_df['side'] == 'Buy']\n",
    "    sell_orders = curr_df[curr_df['side'] == 'Sell']\n",
    "\n",
    "    total_buy = buy_orders['homeNotional'].sum()\n",
    "    total_sell = sell_orders['homeNotional'].sum()\n",
    "    total = total_buy + total_sell\n",
    "\n",
    "    ser['buy_percentage'] = total_buy/total\n",
    "    ser['buy_volume'] = total_buy\n",
    "    ser['all_volume'] = total\n",
    "    \n",
    "    readable_bins = []\n",
    "    \n",
    "\n",
    "    readable_bins = [0, 2, 10, np.inf]\n",
    "        \n",
    "    readable_labels = ['small', 'medium', 'large']\n",
    "    curr_df['new_range'] = pd.cut(curr_df['homeNotional'], readable_bins, include_lowest=True, labels=readable_labels).astype(str)\n",
    "    \n",
    "        \n",
    "    for curr_range in set(readable_labels):\n",
    "        group = curr_df[curr_df['new_range'] == curr_range]\n",
    "        ser[\"percentage_{}\".format(curr_range)] = group['homeNotional'].sum()/total\n",
    "        buy_orders = group[group['side'] == 'Buy']\n",
    "        ser['buy_percentage_{}'.format(curr_range)] = (buy_orders['homeNotional'].sum())/group['homeNotional'].sum()\n",
    "\n",
    "    \n",
    "        \n",
    "    return pd.Series(ser)\n",
    "\n",
    "def get_features_from_sig(df):\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "    minute_only = df['timestamp'].dt.minute.astype(str)\n",
    "    minute_only_two = minute_only.apply(lambda x: str(x)[1:]) #there is a mistake here.\n",
    "    df = df[~((minute_only == '9') | (minute_only_two == '9') | (minute_only == '8')  | (minute_only_two == '8'))]\n",
    "\n",
    "    features = df.groupby(pd.Grouper(key='timestamp', freq=\"10Min\", label='left')).apply(get_features)\n",
    "    features = features.reset_index()\n",
    "\n",
    "    features['timestamp'] = pd.to_datetime(features['timestamp'])\n",
    "    features = features.drop_duplicates(subset=['timestamp'])\n",
    "    features = features.sort_values('timestamp')\n",
    "    features = features.dropna()\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_date = pd.read_sql('SELECT timestamp FROM trades ORDER BY timestamp DESC LIMIT 1', engine).iloc[0]['timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2021-01-19 04:15:57')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df = pd.DataFrame(pd.Series({'Time': last_date})).T\n",
    "prev_date = time_df.groupby(pd.Grouper(key='Time', freq=\"10Min\", label='left')).sum().index[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2021-01-19 04:10:00', freq='10T')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "minute = str(last_date.time().minute)\n",
    "\n",
    "if len(minute) == 1:\n",
    "    minute_only = int(minute)\n",
    "else:\n",
    "    minute_only = int(minute[1:])\n",
    "    \n",
    "if (minute_only <= 8):\n",
    "    prev_date = prev_date - pd.Timedelta(minutes=10)\n",
    "\n",
    "have_till = prev_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2021-01-19 04:00:00', freq='10T')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "have_till"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql('trades', con=engine)\n",
    "\n",
    "\n",
    "\n",
    "df = df[df['timestamp'] < have_till]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove already calculated\n",
    "startTime = df.iloc[0]['timestamp']\n",
    "\n",
    "time_df = pd.DataFrame(pd.Series({'Time': startTime})).T\n",
    "startTime = time_df.groupby(pd.Grouper(key='Time', freq=\"10Min\", label='left')).sum().index[0]\n",
    "\n",
    "\n",
    "\n",
    "if os.path.isfile('data/features.csv'):\n",
    "    startTime = pd.to_datetime(pd.read_csv('data/features.csv').iloc[-1]['timestamp']) + pd.Timedelta(minutes=10)\n",
    "\n",
    "df = df[df['timestamp'] >= startTime]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-990a85e2f421>:53: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ser['buy_percentage_{}'.format(curr_range)] = (buy_orders['homeNotional'].sum())/group['homeNotional'].sum()\n",
      "<ipython-input-4-990a85e2f421>:53: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ser['buy_percentage_{}'.format(curr_range)] = (buy_orders['homeNotional'].sum())/group['homeNotional'].sum()\n",
      "<ipython-input-4-990a85e2f421>:53: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ser['buy_percentage_{}'.format(curr_range)] = (buy_orders['homeNotional'].sum())/group['homeNotional'].sum()\n",
      "<ipython-input-4-990a85e2f421>:53: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ser['buy_percentage_{}'.format(curr_range)] = (buy_orders['homeNotional'].sum())/group['homeNotional'].sum()\n"
     ]
    }
   ],
   "source": [
    "#calculate and save features\n",
    "df = get_significant_traders(df)\n",
    "features = get_features_from_sig(df)\n",
    "\n",
    "features['change'] = ((features['close'] - features['open'])/features['open']) * 100\n",
    "features = features[['timestamp', 'open', 'high', 'low', 'close', 'volume', 'change', 'percentage_large', 'buy_percentage_large']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('data/features.csv'):\n",
    "    old_features = pd.read_csv('data/features.csv')\n",
    "    old_features['timestamp'] = pd.to_datetime(old_features['timestamp'])\n",
    "    features = pd.concat([old_features, features])\n",
    "    \n",
    "features['macd'] = ta.trend.macd_signal(features['close'])\n",
    "features['rsi'] = ta.momentum.rsi(features['close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if os.path.isfile('data/features.csv'):\n",
    "    features.to_csv('data/features.csv', header=None, mode='a', index=None)\n",
    "else:\n",
    "    features.to_csv('data/features.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv('data/features.csv')\n",
    "features['timestamp'] = pd.to_datetime(features['timestamp'])\n",
    "dupe = features.iloc[-1]\n",
    "dupe['timestamp'] = dupe['timestamp'] + pd.Timedelta(minutes=10)\n",
    "features = features.append(dupe, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now backtest and get current position passing parameters as value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run update_trade every 7th minute and at start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#after done, run update trade again and backtest verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python38264bit5e026c37115b47dab948fc9d59355aca"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
